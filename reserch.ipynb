{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQuz-CxvjOBn",
        "outputId": "1012bb41-6922-40b2-da39-8b4640369523"
      },
      "outputs": [],
      "source": [
        "# !pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !mkdir -p {HOME}/data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **People Tracking**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S9xx4BvjSlu",
        "outputId": "ec268a8c-4cc5-41ed-e3b8-62a2a6ff00fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "video 1/1 (frame 1/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 206.5ms\n",
            "video 1/1 (frame 2/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 234.6ms\n",
            "video 1/1 (frame 3/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 204.6ms\n",
            "video 1/1 (frame 4/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 201.0ms\n",
            "video 1/1 (frame 5/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 198.2ms\n",
            "video 1/1 (frame 6/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 184.5ms\n",
            "video 1/1 (frame 7/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 190.5ms\n",
            "video 1/1 (frame 8/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 250.1ms\n",
            "video 1/1 (frame 9/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 261.0ms\n",
            "video 1/1 (frame 10/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 242.2ms\n",
            "video 1/1 (frame 11/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 242.2ms\n",
            "video 1/1 (frame 12/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 259.0ms\n",
            "video 1/1 (frame 13/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 32 persons, 249.1ms\n",
            "video 1/1 (frame 14/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 32 persons, 243.0ms\n",
            "video 1/1 (frame 15/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 235.2ms\n",
            "video 1/1 (frame 16/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 243.2ms\n",
            "video 1/1 (frame 17/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 233.4ms\n",
            "video 1/1 (frame 18/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 32 persons, 372.7ms\n",
            "video 1/1 (frame 19/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 32 persons, 297.3ms\n",
            "video 1/1 (frame 20/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 352.1ms\n",
            "video 1/1 (frame 21/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 405.4ms\n",
            "video 1/1 (frame 22/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 299.0ms\n",
            "video 1/1 (frame 23/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 333.5ms\n",
            "video 1/1 (frame 24/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 305.8ms\n",
            "video 1/1 (frame 25/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 359.5ms\n",
            "video 1/1 (frame 26/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 297.0ms\n",
            "video 1/1 (frame 27/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 319.7ms\n",
            "video 1/1 (frame 28/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 290.9ms\n",
            "video 1/1 (frame 29/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 315.7ms\n",
            "video 1/1 (frame 30/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 269.0ms\n",
            "video 1/1 (frame 31/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 254.0ms\n",
            "video 1/1 (frame 32/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 257.3ms\n",
            "video 1/1 (frame 33/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 305.0ms\n",
            "video 1/1 (frame 34/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 338.5ms\n",
            "video 1/1 (frame 35/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 291.0ms\n",
            "video 1/1 (frame 36/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 314.3ms\n",
            "video 1/1 (frame 37/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 279.0ms\n",
            "video 1/1 (frame 38/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 246.9ms\n",
            "video 1/1 (frame 39/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 242.4ms\n",
            "video 1/1 (frame 40/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 250.5ms\n",
            "video 1/1 (frame 41/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 221.8ms\n",
            "video 1/1 (frame 42/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 187.8ms\n",
            "video 1/1 (frame 43/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 203.9ms\n",
            "video 1/1 (frame 44/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 197.9ms\n",
            "video 1/1 (frame 45/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 200.3ms\n",
            "video 1/1 (frame 46/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 251.5ms\n",
            "video 1/1 (frame 47/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 246.7ms\n",
            "video 1/1 (frame 48/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 261.1ms\n",
            "video 1/1 (frame 49/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 39 persons, 258.1ms\n",
            "video 1/1 (frame 50/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 39 persons, 243.6ms\n",
            "video 1/1 (frame 51/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 39 persons, 240.2ms\n",
            "video 1/1 (frame 52/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 38 persons, 244.6ms\n",
            "video 1/1 (frame 53/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 38 persons, 242.1ms\n",
            "video 1/1 (frame 54/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 38 persons, 294.6ms\n",
            "video 1/1 (frame 55/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 38 persons, 248.4ms\n",
            "video 1/1 (frame 56/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 38 persons, 241.9ms\n",
            "video 1/1 (frame 57/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 38 persons, 246.7ms\n",
            "video 1/1 (frame 58/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 38 persons, 236.0ms\n",
            "video 1/1 (frame 59/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 38 persons, 253.4ms\n",
            "video 1/1 (frame 60/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 265.2ms\n",
            "video 1/1 (frame 61/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 278.9ms\n",
            "video 1/1 (frame 62/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 242.6ms\n",
            "video 1/1 (frame 63/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 272.0ms\n",
            "video 1/1 (frame 64/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 265.5ms\n",
            "video 1/1 (frame 65/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 255.5ms\n",
            "video 1/1 (frame 66/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 240.5ms\n",
            "video 1/1 (frame 67/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 249.4ms\n",
            "video 1/1 (frame 68/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 247.6ms\n",
            "video 1/1 (frame 69/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 259.0ms\n",
            "video 1/1 (frame 70/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 237.0ms\n",
            "video 1/1 (frame 71/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 241.9ms\n",
            "video 1/1 (frame 72/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 242.8ms\n",
            "video 1/1 (frame 73/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 246.3ms\n",
            "video 1/1 (frame 74/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 272.2ms\n",
            "video 1/1 (frame 75/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 255.0ms\n",
            "video 1/1 (frame 76/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 262.5ms\n",
            "video 1/1 (frame 77/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 257.2ms\n",
            "video 1/1 (frame 78/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 248.8ms\n",
            "video 1/1 (frame 79/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 239.1ms\n",
            "video 1/1 (frame 80/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 245.0ms\n",
            "video 1/1 (frame 81/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 253.7ms\n",
            "video 1/1 (frame 82/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 247.9ms\n",
            "video 1/1 (frame 83/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 269.2ms\n",
            "video 1/1 (frame 84/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 315.1ms\n",
            "video 1/1 (frame 85/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 250.8ms\n",
            "video 1/1 (frame 86/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 249.9ms\n",
            "video 1/1 (frame 87/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 260.4ms\n",
            "video 1/1 (frame 88/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 244.2ms\n",
            "video 1/1 (frame 89/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 38 persons, 247.7ms\n",
            "video 1/1 (frame 90/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 252.8ms\n",
            "video 1/1 (frame 91/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 246.7ms\n",
            "video 1/1 (frame 92/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 252.2ms\n",
            "video 1/1 (frame 93/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 38 persons, 243.1ms\n",
            "video 1/1 (frame 94/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 38 persons, 251.8ms\n",
            "video 1/1 (frame 95/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 376.7ms\n",
            "video 1/1 (frame 96/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 248.4ms\n",
            "video 1/1 (frame 97/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 37 persons, 247.3ms\n",
            "video 1/1 (frame 98/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 242.4ms\n",
            "video 1/1 (frame 99/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 251.2ms\n",
            "video 1/1 (frame 100/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 246.6ms\n",
            "video 1/1 (frame 101/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 240.5ms\n",
            "video 1/1 (frame 102/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 36 persons, 244.0ms\n",
            "video 1/1 (frame 103/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 259.2ms\n",
            "video 1/1 (frame 104/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 35 persons, 245.8ms\n",
            "video 1/1 (frame 105/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 239.8ms\n",
            "video 1/1 (frame 106/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 259.7ms\n",
            "video 1/1 (frame 107/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 242.0ms\n",
            "video 1/1 (frame 108/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 203.9ms\n",
            "video 1/1 (frame 109/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 189.7ms\n",
            "video 1/1 (frame 110/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 203.9ms\n",
            "video 1/1 (frame 111/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 218.6ms\n",
            "video 1/1 (frame 112/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 244.8ms\n",
            "video 1/1 (frame 113/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 271.1ms\n",
            "video 1/1 (frame 114/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 250.5ms\n",
            "video 1/1 (frame 115/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 244.4ms\n",
            "video 1/1 (frame 116/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 32 persons, 246.2ms\n",
            "video 1/1 (frame 117/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 32 persons, 246.3ms\n",
            "video 1/1 (frame 118/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 243.2ms\n",
            "video 1/1 (frame 119/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 236.2ms\n",
            "video 1/1 (frame 120/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 34 persons, 247.1ms\n",
            "video 1/1 (frame 121/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 33 persons, 243.9ms\n",
            "video 1/1 (frame 122/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 32 persons, 245.2ms\n",
            "video 1/1 (frame 123/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 32 persons, 246.1ms\n",
            "video 1/1 (frame 124/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 32 persons, 241.6ms\n",
            "video 1/1 (frame 125/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 32 persons, 250.6ms\n",
            "video 1/1 (frame 126/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 246.0ms\n",
            "video 1/1 (frame 127/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 255.1ms\n",
            "video 1/1 (frame 128/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 251.7ms\n",
            "video 1/1 (frame 129/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 256.2ms\n",
            "video 1/1 (frame 130/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 243.7ms\n",
            "video 1/1 (frame 131/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 243.9ms\n",
            "video 1/1 (frame 132/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 257.7ms\n",
            "video 1/1 (frame 133/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 256.5ms\n",
            "video 1/1 (frame 134/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 254.7ms\n",
            "video 1/1 (frame 135/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 243.4ms\n",
            "video 1/1 (frame 136/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 258.3ms\n",
            "video 1/1 (frame 137/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 248.4ms\n",
            "video 1/1 (frame 138/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 242.9ms\n",
            "video 1/1 (frame 139/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 243.7ms\n",
            "video 1/1 (frame 140/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 244.3ms\n",
            "video 1/1 (frame 141/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 247.4ms\n",
            "video 1/1 (frame 142/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 245.8ms\n",
            "video 1/1 (frame 143/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 248.2ms\n",
            "video 1/1 (frame 144/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 246.5ms\n",
            "video 1/1 (frame 145/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 266.7ms\n",
            "video 1/1 (frame 146/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 255.0ms\n",
            "video 1/1 (frame 147/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 241.8ms\n",
            "video 1/1 (frame 148/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 251.8ms\n",
            "video 1/1 (frame 149/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 253.2ms\n",
            "video 1/1 (frame 150/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 253.2ms\n",
            "video 1/1 (frame 151/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 246.1ms\n",
            "video 1/1 (frame 152/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 238.2ms\n",
            "video 1/1 (frame 153/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 244.1ms\n",
            "video 1/1 (frame 154/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 252.0ms\n",
            "video 1/1 (frame 155/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 313.5ms\n",
            "video 1/1 (frame 156/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 255.5ms\n",
            "video 1/1 (frame 157/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 256.5ms\n",
            "video 1/1 (frame 158/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 260.6ms\n",
            "video 1/1 (frame 159/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 250.6ms\n",
            "video 1/1 (frame 160/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 323.1ms\n",
            "video 1/1 (frame 161/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 287.9ms\n",
            "video 1/1 (frame 162/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 303.6ms\n",
            "video 1/1 (frame 163/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 361.2ms\n",
            "video 1/1 (frame 164/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 286.7ms\n",
            "video 1/1 (frame 165/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 254.0ms\n",
            "video 1/1 (frame 166/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 268.4ms\n",
            "video 1/1 (frame 167/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 257.8ms\n",
            "video 1/1 (frame 168/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 249.9ms\n",
            "video 1/1 (frame 169/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 253.5ms\n",
            "video 1/1 (frame 170/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 289.8ms\n",
            "video 1/1 (frame 171/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 265.9ms\n",
            "video 1/1 (frame 172/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 354.5ms\n",
            "video 1/1 (frame 173/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 271.4ms\n",
            "video 1/1 (frame 174/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 266.0ms\n",
            "video 1/1 (frame 175/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 256.9ms\n",
            "video 1/1 (frame 176/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 243.0ms\n",
            "video 1/1 (frame 177/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 281.7ms\n",
            "video 1/1 (frame 178/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 262.5ms\n",
            "video 1/1 (frame 179/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 258.4ms\n",
            "video 1/1 (frame 180/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 257.8ms\n",
            "video 1/1 (frame 181/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 268.9ms\n",
            "video 1/1 (frame 182/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 272.0ms\n",
            "video 1/1 (frame 183/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 273.1ms\n",
            "video 1/1 (frame 184/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 274.5ms\n",
            "video 1/1 (frame 185/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 251.5ms\n",
            "video 1/1 (frame 186/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 249.5ms\n",
            "video 1/1 (frame 187/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 258.5ms\n",
            "video 1/1 (frame 188/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 247.0ms\n",
            "video 1/1 (frame 189/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 256.4ms\n",
            "video 1/1 (frame 190/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 248.7ms\n",
            "video 1/1 (frame 191/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 257.4ms\n",
            "video 1/1 (frame 192/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 255.2ms\n",
            "video 1/1 (frame 193/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 248.9ms\n",
            "video 1/1 (frame 194/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 264.6ms\n",
            "video 1/1 (frame 195/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 257.9ms\n",
            "video 1/1 (frame 196/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 253.9ms\n",
            "video 1/1 (frame 197/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 255.4ms\n",
            "video 1/1 (frame 198/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 265.1ms\n",
            "video 1/1 (frame 199/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 262.6ms\n",
            "video 1/1 (frame 200/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 260.6ms\n",
            "video 1/1 (frame 201/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 31 persons, 264.5ms\n",
            "video 1/1 (frame 202/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 269.7ms\n",
            "video 1/1 (frame 203/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 30 persons, 267.7ms\n",
            "video 1/1 (frame 204/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 260.9ms\n",
            "video 1/1 (frame 205/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 256.9ms\n",
            "video 1/1 (frame 206/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 270.5ms\n",
            "video 1/1 (frame 207/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 271.5ms\n",
            "video 1/1 (frame 208/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 251.3ms\n",
            "video 1/1 (frame 209/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 258.5ms\n",
            "video 1/1 (frame 210/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 264.4ms\n",
            "video 1/1 (frame 211/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 245.8ms\n",
            "video 1/1 (frame 212/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 248.5ms\n",
            "video 1/1 (frame 213/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 236.8ms\n",
            "video 1/1 (frame 214/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 247.5ms\n",
            "video 1/1 (frame 215/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 245.5ms\n",
            "video 1/1 (frame 216/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 252.6ms\n",
            "video 1/1 (frame 217/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 257.2ms\n",
            "video 1/1 (frame 218/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 244.6ms\n",
            "video 1/1 (frame 219/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 240.6ms\n",
            "video 1/1 (frame 220/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 260.0ms\n",
            "video 1/1 (frame 221/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 277.8ms\n",
            "video 1/1 (frame 222/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 275.7ms\n",
            "video 1/1 (frame 223/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 275.8ms\n",
            "video 1/1 (frame 224/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 256.9ms\n",
            "video 1/1 (frame 225/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 257.6ms\n",
            "video 1/1 (frame 226/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 276.7ms\n",
            "video 1/1 (frame 227/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 247.3ms\n",
            "video 1/1 (frame 228/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 257.2ms\n",
            "video 1/1 (frame 229/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 278.1ms\n",
            "video 1/1 (frame 230/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 259.9ms\n",
            "video 1/1 (frame 231/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 252.1ms\n",
            "video 1/1 (frame 232/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 252.2ms\n",
            "video 1/1 (frame 233/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 266.2ms\n",
            "video 1/1 (frame 234/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 254.0ms\n",
            "video 1/1 (frame 235/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 250.9ms\n",
            "video 1/1 (frame 236/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 262.2ms\n",
            "video 1/1 (frame 237/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 257.3ms\n",
            "video 1/1 (frame 238/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 249.0ms\n",
            "video 1/1 (frame 239/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 246.1ms\n",
            "video 1/1 (frame 240/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 240.1ms\n",
            "video 1/1 (frame 241/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 242.9ms\n",
            "video 1/1 (frame 242/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 314.6ms\n",
            "video 1/1 (frame 243/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 240.9ms\n",
            "video 1/1 (frame 244/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 250.3ms\n",
            "video 1/1 (frame 245/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 252.7ms\n",
            "video 1/1 (frame 246/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 23 persons, 240.4ms\n",
            "video 1/1 (frame 247/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 23 persons, 250.9ms\n",
            "video 1/1 (frame 248/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 23 persons, 375.1ms\n",
            "video 1/1 (frame 249/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 253.0ms\n",
            "video 1/1 (frame 250/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 248.3ms\n",
            "video 1/1 (frame 251/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 259.9ms\n",
            "video 1/1 (frame 252/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 244.5ms\n",
            "video 1/1 (frame 253/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 244.6ms\n",
            "video 1/1 (frame 254/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 239.1ms\n",
            "video 1/1 (frame 255/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 23 persons, 244.0ms\n",
            "video 1/1 (frame 256/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 23 persons, 247.3ms\n",
            "video 1/1 (frame 257/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 241.4ms\n",
            "video 1/1 (frame 258/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 279.3ms\n",
            "video 1/1 (frame 259/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 254.2ms\n",
            "video 1/1 (frame 260/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 23 persons, 258.9ms\n",
            "video 1/1 (frame 261/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 23 persons, 253.1ms\n",
            "video 1/1 (frame 262/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 251.9ms\n",
            "video 1/1 (frame 263/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 253.0ms\n",
            "video 1/1 (frame 264/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 248.6ms\n",
            "video 1/1 (frame 265/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 270.4ms\n",
            "video 1/1 (frame 266/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 250.1ms\n",
            "video 1/1 (frame 267/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 252.7ms\n",
            "video 1/1 (frame 268/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 269.8ms\n",
            "video 1/1 (frame 269/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 250.5ms\n",
            "video 1/1 (frame 270/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 264.1ms\n",
            "video 1/1 (frame 271/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 262.4ms\n",
            "video 1/1 (frame 272/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 256.4ms\n",
            "video 1/1 (frame 273/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 268.5ms\n",
            "video 1/1 (frame 274/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 261.5ms\n",
            "video 1/1 (frame 275/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 296.0ms\n",
            "video 1/1 (frame 276/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 262.3ms\n",
            "video 1/1 (frame 277/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 262.3ms\n",
            "video 1/1 (frame 278/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 322.3ms\n",
            "video 1/1 (frame 279/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 266.2ms\n",
            "video 1/1 (frame 280/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 255.7ms\n",
            "video 1/1 (frame 281/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 254.8ms\n",
            "video 1/1 (frame 282/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 257.5ms\n",
            "video 1/1 (frame 283/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 256.4ms\n",
            "video 1/1 (frame 284/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 245.8ms\n",
            "video 1/1 (frame 285/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 336.3ms\n",
            "video 1/1 (frame 286/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 268.3ms\n",
            "video 1/1 (frame 287/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 248.7ms\n",
            "video 1/1 (frame 288/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 241.3ms\n",
            "video 1/1 (frame 289/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 242.5ms\n",
            "video 1/1 (frame 290/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 246.3ms\n",
            "video 1/1 (frame 291/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 253.3ms\n",
            "video 1/1 (frame 292/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 242.3ms\n",
            "video 1/1 (frame 293/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 243.2ms\n",
            "video 1/1 (frame 294/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 249.1ms\n",
            "video 1/1 (frame 295/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 253.4ms\n",
            "video 1/1 (frame 296/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 251.0ms\n",
            "video 1/1 (frame 297/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 259.4ms\n",
            "video 1/1 (frame 298/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 247.4ms\n",
            "video 1/1 (frame 299/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 247.7ms\n",
            "video 1/1 (frame 300/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 245.6ms\n",
            "video 1/1 (frame 301/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 249.7ms\n",
            "video 1/1 (frame 302/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 246.6ms\n",
            "video 1/1 (frame 303/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 264.5ms\n",
            "video 1/1 (frame 304/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 246.7ms\n",
            "video 1/1 (frame 305/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 242.7ms\n",
            "video 1/1 (frame 306/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 260.4ms\n",
            "video 1/1 (frame 307/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 240.9ms\n",
            "video 1/1 (frame 308/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 245.0ms\n",
            "video 1/1 (frame 309/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 248.2ms\n",
            "video 1/1 (frame 310/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 248.3ms\n",
            "video 1/1 (frame 311/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 29 persons, 257.2ms\n",
            "video 1/1 (frame 312/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 253.7ms\n",
            "video 1/1 (frame 313/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 251.2ms\n",
            "video 1/1 (frame 314/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 287.2ms\n",
            "video 1/1 (frame 315/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 261.4ms\n",
            "video 1/1 (frame 316/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 247.1ms\n",
            "video 1/1 (frame 317/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 251.2ms\n",
            "video 1/1 (frame 318/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 258.6ms\n",
            "video 1/1 (frame 319/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 262.2ms\n",
            "video 1/1 (frame 320/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 256.8ms\n",
            "video 1/1 (frame 321/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 253.4ms\n",
            "video 1/1 (frame 322/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 263.9ms\n",
            "video 1/1 (frame 323/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 254.4ms\n",
            "video 1/1 (frame 324/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 251.4ms\n",
            "video 1/1 (frame 325/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 258.6ms\n",
            "video 1/1 (frame 326/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 333.6ms\n",
            "video 1/1 (frame 327/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 269.4ms\n",
            "video 1/1 (frame 328/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 260.8ms\n",
            "video 1/1 (frame 329/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 248.1ms\n",
            "video 1/1 (frame 330/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 246.6ms\n",
            "video 1/1 (frame 331/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 248.7ms\n",
            "video 1/1 (frame 332/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 251.5ms\n",
            "video 1/1 (frame 333/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 24 persons, 244.7ms\n",
            "video 1/1 (frame 334/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 25 persons, 256.1ms\n",
            "video 1/1 (frame 335/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 26 persons, 276.9ms\n",
            "video 1/1 (frame 336/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 257.6ms\n",
            "video 1/1 (frame 337/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 257.3ms\n",
            "video 1/1 (frame 338/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 264.9ms\n",
            "video 1/1 (frame 339/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 255.0ms\n",
            "video 1/1 (frame 340/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 28 persons, 249.4ms\n",
            "video 1/1 (frame 341/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 249.6ms\n",
            "video 1/1 (frame 342/343) /media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/data/people_walking.webm: 384x640 27 persons, 239.5ms\n",
            "Speed: 3.8ms preprocess, 257.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track5\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load an official or custom model\n",
        "\n",
        "# model = YOLO(\"yolov8n.pt\")  # Load an official Detect model\n",
        "# model = YOLO(\"yolov8n-seg.pt\")  # Load an official Segment model\n",
        "# model = YOLO(\"yolov8n-pose.pt\")  # Load an official Pose model\n",
        "model = YOLO(\"model/PeopleDetector.pt\")  # Load a custom trained model\n",
        "\n",
        "# Perform tracking with the model\n",
        "# results = model.track(\"/content/sample_video1.mp4\", show=True, save=True)  # Tracking with default tracker\n",
        "results = model.track(\"data/people_walking.webm\",conf=0.3, iou=0.5, show=True, save=True, tracker=\"bytetrack.yaml\")  # with ByteTrack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aGpgpyZPpBBW"
      },
      "outputs": [],
      "source": [
        "#from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Plotting tracks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "09-eptG4oehU",
        "outputId": "dc050568-7ea4-470d-ec98-a5f73d70b8a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 384x640 25 persons, 203.7ms\n",
            "Speed: 2.4ms preprocess, 203.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 237.1ms\n",
            "Speed: 3.5ms preprocess, 237.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 199.0ms\n",
            "Speed: 4.4ms preprocess, 199.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 218.6ms\n",
            "Speed: 4.0ms preprocess, 218.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 203.1ms\n",
            "Speed: 3.1ms preprocess, 203.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 230.9ms\n",
            "Speed: 4.1ms preprocess, 230.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 207.1ms\n",
            "Speed: 3.1ms preprocess, 207.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 187.7ms\n",
            "Speed: 3.0ms preprocess, 187.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 189.5ms\n",
            "Speed: 3.4ms preprocess, 189.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 192.0ms\n",
            "Speed: 4.2ms preprocess, 192.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 205.5ms\n",
            "Speed: 2.9ms preprocess, 205.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 200.2ms\n",
            "Speed: 2.5ms preprocess, 200.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 200.0ms\n",
            "Speed: 3.0ms preprocess, 200.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 196.4ms\n",
            "Speed: 5.5ms preprocess, 196.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 203.5ms\n",
            "Speed: 3.4ms preprocess, 203.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 222.6ms\n",
            "Speed: 5.8ms preprocess, 222.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 198.5ms\n",
            "Speed: 4.8ms preprocess, 198.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 189.8ms\n",
            "Speed: 3.1ms preprocess, 189.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 204.4ms\n",
            "Speed: 3.5ms preprocess, 204.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 244.3ms\n",
            "Speed: 3.5ms preprocess, 244.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 186.3ms\n",
            "Speed: 4.7ms preprocess, 186.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 189.4ms\n",
            "Speed: 3.2ms preprocess, 189.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 186.4ms\n",
            "Speed: 2.6ms preprocess, 186.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 196.7ms\n",
            "Speed: 2.5ms preprocess, 196.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 179.2ms\n",
            "Speed: 2.4ms preprocess, 179.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 197.9ms\n",
            "Speed: 2.8ms preprocess, 197.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 210.2ms\n",
            "Speed: 2.8ms preprocess, 210.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 195.5ms\n",
            "Speed: 3.5ms preprocess, 195.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 212.9ms\n",
            "Speed: 3.9ms preprocess, 212.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 225.3ms\n",
            "Speed: 4.3ms preprocess, 225.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 199.0ms\n",
            "Speed: 2.7ms preprocess, 199.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 186.6ms\n",
            "Speed: 4.0ms preprocess, 186.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 231.1ms\n",
            "Speed: 3.5ms preprocess, 231.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 247.0ms\n",
            "Speed: 3.3ms preprocess, 247.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 242.9ms\n",
            "Speed: 2.9ms preprocess, 242.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 245.2ms\n",
            "Speed: 3.0ms preprocess, 245.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 237.6ms\n",
            "Speed: 3.6ms preprocess, 237.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 238.9ms\n",
            "Speed: 3.9ms preprocess, 238.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 231.5ms\n",
            "Speed: 3.9ms preprocess, 231.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 232.8ms\n",
            "Speed: 3.2ms preprocess, 232.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 242.1ms\n",
            "Speed: 4.0ms preprocess, 242.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 251.6ms\n",
            "Speed: 4.1ms preprocess, 251.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 285.4ms\n",
            "Speed: 10.8ms preprocess, 285.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 266.6ms\n",
            "Speed: 5.9ms preprocess, 266.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 300.1ms\n",
            "Speed: 3.7ms preprocess, 300.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 246.0ms\n",
            "Speed: 2.7ms preprocess, 246.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 275.5ms\n",
            "Speed: 4.5ms preprocess, 275.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 247.1ms\n",
            "Speed: 3.8ms preprocess, 247.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 250.9ms\n",
            "Speed: 4.4ms preprocess, 250.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 248.5ms\n",
            "Speed: 3.8ms preprocess, 248.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 249.4ms\n",
            "Speed: 4.6ms preprocess, 249.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 235.4ms\n",
            "Speed: 4.1ms preprocess, 235.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 238.2ms\n",
            "Speed: 4.3ms preprocess, 238.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 256.1ms\n",
            "Speed: 4.3ms preprocess, 256.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 278.7ms\n",
            "Speed: 5.2ms preprocess, 278.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 250.3ms\n",
            "Speed: 3.8ms preprocess, 250.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 245.7ms\n",
            "Speed: 2.8ms preprocess, 245.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 256.2ms\n",
            "Speed: 3.5ms preprocess, 256.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 252.4ms\n",
            "Speed: 3.6ms preprocess, 252.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 250.3ms\n",
            "Speed: 3.2ms preprocess, 250.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 254.8ms\n",
            "Speed: 3.5ms preprocess, 254.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 242.9ms\n",
            "Speed: 3.4ms preprocess, 242.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 246.3ms\n",
            "Speed: 3.3ms preprocess, 246.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 250.6ms\n",
            "Speed: 3.6ms preprocess, 250.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 251.5ms\n",
            "Speed: 4.0ms preprocess, 251.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 233.8ms\n",
            "Speed: 2.5ms preprocess, 233.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 243.1ms\n",
            "Speed: 3.1ms preprocess, 243.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 252.0ms\n",
            "Speed: 4.9ms preprocess, 252.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 398.0ms\n",
            "Speed: 9.9ms preprocess, 398.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 248.6ms\n",
            "Speed: 4.0ms preprocess, 248.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 240.4ms\n",
            "Speed: 3.7ms preprocess, 240.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 249.9ms\n",
            "Speed: 3.7ms preprocess, 249.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 257.4ms\n",
            "Speed: 3.6ms preprocess, 257.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 292.4ms\n",
            "Speed: 2.8ms preprocess, 292.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 262.3ms\n",
            "Speed: 3.9ms preprocess, 262.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 212.8ms\n",
            "Speed: 5.2ms preprocess, 212.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 204.2ms\n",
            "Speed: 4.6ms preprocess, 204.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 186.2ms\n",
            "Speed: 3.5ms preprocess, 186.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 211.3ms\n",
            "Speed: 6.7ms preprocess, 211.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 198.6ms\n",
            "Speed: 2.4ms preprocess, 198.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 214.4ms\n",
            "Speed: 4.0ms preprocess, 214.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 205.3ms\n",
            "Speed: 3.3ms preprocess, 205.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 238.2ms\n",
            "Speed: 3.6ms preprocess, 238.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 289.2ms\n",
            "Speed: 2.4ms preprocess, 289.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 270.2ms\n",
            "Speed: 4.6ms preprocess, 270.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 254.8ms\n",
            "Speed: 3.7ms preprocess, 254.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 250.0ms\n",
            "Speed: 3.5ms preprocess, 250.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 261.2ms\n",
            "Speed: 3.9ms preprocess, 261.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 254.6ms\n",
            "Speed: 3.4ms preprocess, 254.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 267.1ms\n",
            "Speed: 5.5ms preprocess, 267.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 299.9ms\n",
            "Speed: 3.7ms preprocess, 299.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 272.9ms\n",
            "Speed: 5.2ms preprocess, 272.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 263.3ms\n",
            "Speed: 4.2ms preprocess, 263.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 272.7ms\n",
            "Speed: 3.8ms preprocess, 272.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 250.1ms\n",
            "Speed: 3.9ms preprocess, 250.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 252.3ms\n",
            "Speed: 3.5ms preprocess, 252.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 243.5ms\n",
            "Speed: 5.1ms preprocess, 243.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 246.7ms\n",
            "Speed: 2.8ms preprocess, 246.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 258.7ms\n",
            "Speed: 4.5ms preprocess, 258.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 273.5ms\n",
            "Speed: 3.5ms preprocess, 273.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 282.6ms\n",
            "Speed: 5.1ms preprocess, 282.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 249.3ms\n",
            "Speed: 3.5ms preprocess, 249.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 250.3ms\n",
            "Speed: 3.5ms preprocess, 250.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 241.7ms\n",
            "Speed: 4.6ms preprocess, 241.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 244.7ms\n",
            "Speed: 4.4ms preprocess, 244.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 249.8ms\n",
            "Speed: 4.2ms preprocess, 249.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 281.6ms\n",
            "Speed: 4.1ms preprocess, 281.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 326.4ms\n",
            "Speed: 3.5ms preprocess, 326.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 320.3ms\n",
            "Speed: 8.6ms preprocess, 320.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 259.8ms\n",
            "Speed: 4.9ms preprocess, 259.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 244.7ms\n",
            "Speed: 3.6ms preprocess, 244.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 232.9ms\n",
            "Speed: 4.0ms preprocess, 232.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 237.0ms\n",
            "Speed: 3.9ms preprocess, 237.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 244.8ms\n",
            "Speed: 2.9ms preprocess, 244.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 245.5ms\n",
            "Speed: 3.9ms preprocess, 245.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 242.3ms\n",
            "Speed: 3.5ms preprocess, 242.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 243.6ms\n",
            "Speed: 3.1ms preprocess, 243.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 240.4ms\n",
            "Speed: 3.4ms preprocess, 240.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 247.5ms\n",
            "Speed: 3.6ms preprocess, 247.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 256.5ms\n",
            "Speed: 4.3ms preprocess, 256.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 256.0ms\n",
            "Speed: 3.8ms preprocess, 256.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 255.6ms\n",
            "Speed: 3.4ms preprocess, 255.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 270.0ms\n",
            "Speed: 3.4ms preprocess, 270.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 253.5ms\n",
            "Speed: 5.1ms preprocess, 253.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 253.5ms\n",
            "Speed: 3.9ms preprocess, 253.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 246.8ms\n",
            "Speed: 3.6ms preprocess, 246.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 238.3ms\n",
            "Speed: 2.3ms preprocess, 238.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 249.1ms\n",
            "Speed: 2.7ms preprocess, 249.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 240.4ms\n",
            "Speed: 3.9ms preprocess, 240.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 238.0ms\n",
            "Speed: 3.5ms preprocess, 238.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 237.1ms\n",
            "Speed: 3.4ms preprocess, 237.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 185.2ms\n",
            "Speed: 2.7ms preprocess, 185.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 197.9ms\n",
            "Speed: 2.1ms preprocess, 197.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 198.5ms\n",
            "Speed: 3.2ms preprocess, 198.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 204.3ms\n",
            "Speed: 3.5ms preprocess, 204.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 236.4ms\n",
            "Speed: 4.0ms preprocess, 236.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 268.8ms\n",
            "Speed: 4.1ms preprocess, 268.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 255.2ms\n",
            "Speed: 4.5ms preprocess, 255.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 252.0ms\n",
            "Speed: 3.4ms preprocess, 252.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 258.7ms\n",
            "Speed: 3.5ms preprocess, 258.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 259.2ms\n",
            "Speed: 3.8ms preprocess, 259.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 388.4ms\n",
            "Speed: 3.0ms preprocess, 388.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 237.4ms\n",
            "Speed: 3.9ms preprocess, 237.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 279.2ms\n",
            "Speed: 3.4ms preprocess, 279.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 270.0ms\n",
            "Speed: 5.4ms preprocess, 270.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 264.1ms\n",
            "Speed: 3.9ms preprocess, 264.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 270.2ms\n",
            "Speed: 5.7ms preprocess, 270.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 269.4ms\n",
            "Speed: 5.5ms preprocess, 269.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 277.4ms\n",
            "Speed: 3.7ms preprocess, 277.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 263.8ms\n",
            "Speed: 3.7ms preprocess, 263.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 297.3ms\n",
            "Speed: 3.8ms preprocess, 297.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 255.7ms\n",
            "Speed: 5.8ms preprocess, 255.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 246.9ms\n",
            "Speed: 4.0ms preprocess, 246.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 250.3ms\n",
            "Speed: 3.7ms preprocess, 250.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 249.8ms\n",
            "Speed: 6.4ms preprocess, 249.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 236.2ms\n",
            "Speed: 4.3ms preprocess, 236.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 246.8ms\n",
            "Speed: 4.8ms preprocess, 246.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 245.8ms\n",
            "Speed: 3.5ms preprocess, 245.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 281.9ms\n",
            "Speed: 4.7ms preprocess, 281.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 249.1ms\n",
            "Speed: 3.3ms preprocess, 249.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 256.3ms\n",
            "Speed: 4.0ms preprocess, 256.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 251.2ms\n",
            "Speed: 4.5ms preprocess, 251.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 245.9ms\n",
            "Speed: 4.1ms preprocess, 245.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 253.1ms\n",
            "Speed: 4.0ms preprocess, 253.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 243.2ms\n",
            "Speed: 3.6ms preprocess, 243.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 265.4ms\n",
            "Speed: 3.6ms preprocess, 265.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 252.6ms\n",
            "Speed: 5.0ms preprocess, 252.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 274.3ms\n",
            "Speed: 3.9ms preprocess, 274.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 253.6ms\n",
            "Speed: 4.3ms preprocess, 253.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 262.5ms\n",
            "Speed: 3.7ms preprocess, 262.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 251.5ms\n",
            "Speed: 4.1ms preprocess, 251.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 263.0ms\n",
            "Speed: 4.3ms preprocess, 263.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 276.3ms\n",
            "Speed: 3.0ms preprocess, 276.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 262.3ms\n",
            "Speed: 4.3ms preprocess, 262.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 213.4ms\n",
            "Speed: 4.1ms preprocess, 213.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 196.6ms\n",
            "Speed: 2.9ms preprocess, 196.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 196.9ms\n",
            "Speed: 4.0ms preprocess, 196.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 191.5ms\n",
            "Speed: 3.8ms preprocess, 191.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 194.6ms\n",
            "Speed: 3.3ms preprocess, 194.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 193.9ms\n",
            "Speed: 3.8ms preprocess, 193.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 194.2ms\n",
            "Speed: 3.3ms preprocess, 194.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 198.3ms\n",
            "Speed: 11.5ms preprocess, 198.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 194.6ms\n",
            "Speed: 3.8ms preprocess, 194.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 256.2ms\n",
            "Speed: 3.4ms preprocess, 256.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 249.0ms\n",
            "Speed: 3.9ms preprocess, 249.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 336.1ms\n",
            "Speed: 6.9ms preprocess, 336.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 258.7ms\n",
            "Speed: 3.8ms preprocess, 258.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 261.8ms\n",
            "Speed: 3.8ms preprocess, 261.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 247.1ms\n",
            "Speed: 3.7ms preprocess, 247.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 258.4ms\n",
            "Speed: 4.4ms preprocess, 258.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 269.1ms\n",
            "Speed: 4.0ms preprocess, 269.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 250.9ms\n",
            "Speed: 3.7ms preprocess, 250.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 256.7ms\n",
            "Speed: 3.9ms preprocess, 256.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 251.0ms\n",
            "Speed: 3.9ms preprocess, 251.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 251.5ms\n",
            "Speed: 3.8ms preprocess, 251.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 252.1ms\n",
            "Speed: 3.6ms preprocess, 252.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 262.3ms\n",
            "Speed: 3.6ms preprocess, 262.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 271.3ms\n",
            "Speed: 3.5ms preprocess, 271.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 286.7ms\n",
            "Speed: 3.9ms preprocess, 286.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 283.1ms\n",
            "Speed: 4.0ms preprocess, 283.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 281.6ms\n",
            "Speed: 4.4ms preprocess, 281.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 264.3ms\n",
            "Speed: 3.8ms preprocess, 264.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 265.2ms\n",
            "Speed: 3.5ms preprocess, 265.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 272.7ms\n",
            "Speed: 3.9ms preprocess, 272.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 262.3ms\n",
            "Speed: 3.8ms preprocess, 262.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 250.9ms\n",
            "Speed: 3.8ms preprocess, 250.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 272.8ms\n",
            "Speed: 4.1ms preprocess, 272.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 251.0ms\n",
            "Speed: 3.7ms preprocess, 251.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 251.3ms\n",
            "Speed: 2.8ms preprocess, 251.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 257.8ms\n",
            "Speed: 2.6ms preprocess, 257.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 255.0ms\n",
            "Speed: 3.6ms preprocess, 255.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 270.3ms\n",
            "Speed: 3.6ms preprocess, 270.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 299.8ms\n",
            "Speed: 5.5ms preprocess, 299.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 274.2ms\n",
            "Speed: 4.2ms preprocess, 274.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 278.2ms\n",
            "Speed: 3.9ms preprocess, 278.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 276.3ms\n",
            "Speed: 2.9ms preprocess, 276.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 252.9ms\n",
            "Speed: 4.5ms preprocess, 252.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 255.0ms\n",
            "Speed: 4.1ms preprocess, 255.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 259.4ms\n",
            "Speed: 4.7ms preprocess, 259.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 269.9ms\n",
            "Speed: 3.6ms preprocess, 269.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 266.5ms\n",
            "Speed: 4.4ms preprocess, 266.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 252.6ms\n",
            "Speed: 3.2ms preprocess, 252.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 285.7ms\n",
            "Speed: 3.8ms preprocess, 285.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 249.3ms\n",
            "Speed: 4.1ms preprocess, 249.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 272.6ms\n",
            "Speed: 4.6ms preprocess, 272.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 267.9ms\n",
            "Speed: 5.5ms preprocess, 267.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 300.5ms\n",
            "Speed: 3.4ms preprocess, 300.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 258.4ms\n",
            "Speed: 4.0ms preprocess, 258.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 263.0ms\n",
            "Speed: 5.0ms preprocess, 263.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 270.6ms\n",
            "Speed: 5.1ms preprocess, 270.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 249.9ms\n",
            "Speed: 5.0ms preprocess, 249.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 242.1ms\n",
            "Speed: 3.9ms preprocess, 242.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 214.7ms\n",
            "Speed: 4.2ms preprocess, 214.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 192.7ms\n",
            "Speed: 4.0ms preprocess, 192.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 264.2ms\n",
            "Speed: 4.0ms preprocess, 264.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 245.2ms\n",
            "Speed: 4.3ms preprocess, 245.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 247.4ms\n",
            "Speed: 4.6ms preprocess, 247.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 243.0ms\n",
            "Speed: 3.9ms preprocess, 243.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 269.4ms\n",
            "Speed: 7.1ms preprocess, 269.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 245.5ms\n",
            "Speed: 4.5ms preprocess, 245.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 255.5ms\n",
            "Speed: 4.8ms preprocess, 255.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 260.3ms\n",
            "Speed: 4.2ms preprocess, 260.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 257.7ms\n",
            "Speed: 3.9ms preprocess, 257.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 245.7ms\n",
            "Speed: 3.6ms preprocess, 245.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 254.1ms\n",
            "Speed: 4.6ms preprocess, 254.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 263.8ms\n",
            "Speed: 3.6ms preprocess, 263.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 273.7ms\n",
            "Speed: 4.1ms preprocess, 273.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 250.9ms\n",
            "Speed: 4.1ms preprocess, 250.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 245.5ms\n",
            "Speed: 3.2ms preprocess, 245.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 249.6ms\n",
            "Speed: 4.0ms preprocess, 249.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 257.2ms\n",
            "Speed: 3.4ms preprocess, 257.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 266.3ms\n",
            "Speed: 4.9ms preprocess, 266.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 257.1ms\n",
            "Speed: 3.5ms preprocess, 257.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 263.1ms\n",
            "Speed: 4.1ms preprocess, 263.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 257.0ms\n",
            "Speed: 4.0ms preprocess, 257.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 259.7ms\n",
            "Speed: 3.1ms preprocess, 259.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 330.8ms\n",
            "Speed: 4.5ms preprocess, 330.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 255.3ms\n",
            "Speed: 3.6ms preprocess, 255.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 243.4ms\n",
            "Speed: 4.8ms preprocess, 243.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 249.9ms\n",
            "Speed: 3.8ms preprocess, 249.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 248.2ms\n",
            "Speed: 4.5ms preprocess, 248.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 249.7ms\n",
            "Speed: 3.5ms preprocess, 249.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 256.2ms\n",
            "Speed: 4.3ms preprocess, 256.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 256.0ms\n",
            "Speed: 3.7ms preprocess, 256.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 253.3ms\n",
            "Speed: 4.4ms preprocess, 253.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 254.1ms\n",
            "Speed: 4.8ms preprocess, 254.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 259.3ms\n",
            "Speed: 4.6ms preprocess, 259.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 246.4ms\n",
            "Speed: 3.1ms preprocess, 246.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 260.7ms\n",
            "Speed: 3.7ms preprocess, 260.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 239.9ms\n",
            "Speed: 3.2ms preprocess, 239.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 245.2ms\n",
            "Speed: 5.1ms preprocess, 245.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 256.2ms\n",
            "Speed: 4.1ms preprocess, 256.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 251.3ms\n",
            "Speed: 3.8ms preprocess, 251.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 249.7ms\n",
            "Speed: 3.9ms preprocess, 249.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 321.0ms\n",
            "Speed: 3.9ms preprocess, 321.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 256.0ms\n",
            "Speed: 5.6ms preprocess, 256.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 253.1ms\n",
            "Speed: 3.1ms preprocess, 253.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 262.9ms\n",
            "Speed: 3.7ms preprocess, 262.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 256.5ms\n",
            "Speed: 4.8ms preprocess, 256.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 255.5ms\n",
            "Speed: 4.0ms preprocess, 255.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 268.9ms\n",
            "Speed: 3.9ms preprocess, 268.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 272.4ms\n",
            "Speed: 3.1ms preprocess, 272.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 250.6ms\n",
            "Speed: 3.6ms preprocess, 250.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 261.1ms\n",
            "Speed: 3.4ms preprocess, 261.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 267.0ms\n",
            "Speed: 3.9ms preprocess, 267.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 245.8ms\n",
            "Speed: 3.8ms preprocess, 245.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 252.1ms\n",
            "Speed: 4.3ms preprocess, 252.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 250.9ms\n",
            "Speed: 3.4ms preprocess, 250.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 250.4ms\n",
            "Speed: 3.8ms preprocess, 250.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 250.4ms\n",
            "Speed: 3.5ms preprocess, 250.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 257.8ms\n",
            "Speed: 3.1ms preprocess, 257.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 254.8ms\n",
            "Speed: 4.9ms preprocess, 254.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 262.9ms\n",
            "Speed: 4.0ms preprocess, 262.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 258.9ms\n",
            "Speed: 4.3ms preprocess, 258.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 250.3ms\n",
            "Speed: 4.2ms preprocess, 250.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 255.3ms\n",
            "Speed: 3.9ms preprocess, 255.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 249.0ms\n",
            "Speed: 2.7ms preprocess, 249.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 242.3ms\n",
            "Speed: 5.3ms preprocess, 242.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 240.9ms\n",
            "Speed: 3.7ms preprocess, 240.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 254.5ms\n",
            "Speed: 3.3ms preprocess, 254.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 247.2ms\n",
            "Speed: 4.9ms preprocess, 247.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 251.1ms\n",
            "Speed: 4.1ms preprocess, 251.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 246.9ms\n",
            "Speed: 4.8ms preprocess, 246.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 257.7ms\n",
            "Speed: 4.2ms preprocess, 257.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 283.6ms\n",
            "Speed: 5.8ms preprocess, 283.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 250.5ms\n",
            "Speed: 4.1ms preprocess, 250.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 253.4ms\n",
            "Speed: 3.6ms preprocess, 253.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 263.7ms\n",
            "Speed: 3.4ms preprocess, 263.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 249.9ms\n",
            "Speed: 3.3ms preprocess, 249.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 247.8ms\n",
            "Speed: 3.9ms preprocess, 247.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 251.7ms\n",
            "Speed: 4.1ms preprocess, 251.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 246.2ms\n",
            "Speed: 5.7ms preprocess, 246.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 380.9ms\n",
            "Speed: 3.6ms preprocess, 380.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 244.6ms\n",
            "Speed: 3.8ms preprocess, 244.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 256.6ms\n",
            "Speed: 3.8ms preprocess, 256.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 248.8ms\n",
            "Speed: 3.2ms preprocess, 248.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 271.9ms\n",
            "Speed: 5.4ms preprocess, 271.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 256.1ms\n",
            "Speed: 3.3ms preprocess, 256.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 251.4ms\n",
            "Speed: 3.7ms preprocess, 251.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 247.0ms\n",
            "Speed: 3.7ms preprocess, 247.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 265.2ms\n",
            "Speed: 3.2ms preprocess, 265.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 251.6ms\n",
            "Speed: 4.6ms preprocess, 251.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 246.6ms\n",
            "Speed: 4.3ms preprocess, 246.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 255.7ms\n",
            "Speed: 3.5ms preprocess, 255.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 269.2ms\n",
            "Speed: 4.1ms preprocess, 269.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 275.5ms\n",
            "Speed: 4.6ms preprocess, 275.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 262.1ms\n",
            "Speed: 4.1ms preprocess, 262.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 249.1ms\n",
            "Speed: 5.5ms preprocess, 249.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 265.3ms\n",
            "Speed: 3.9ms preprocess, 265.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 246.0ms\n",
            "Speed: 3.2ms preprocess, 246.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 243.0ms\n",
            "Speed: 3.7ms preprocess, 243.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 251.4ms\n",
            "Speed: 4.5ms preprocess, 251.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 247.2ms\n",
            "Speed: 5.0ms preprocess, 247.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 255.9ms\n",
            "Speed: 4.3ms preprocess, 255.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 269.1ms\n",
            "Speed: 4.4ms preprocess, 269.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 243.9ms\n",
            "Speed: 3.7ms preprocess, 243.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 252.7ms\n",
            "Speed: 3.8ms preprocess, 252.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 253.2ms\n",
            "Speed: 3.4ms preprocess, 253.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 251.4ms\n",
            "Speed: 3.6ms preprocess, 251.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 246.5ms\n",
            "Speed: 2.8ms preprocess, 246.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 258.7ms\n",
            "Speed: 2.9ms preprocess, 258.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 243.2ms\n",
            "Speed: 4.0ms preprocess, 243.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO(\"model/PeopleDetector.pt\")\n",
        "\n",
        "# Open the video file\n",
        "video_path = \"data/people_walking.webm\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
        "        results = model.track(frame, persist=True, conf=0.3, iou=0.5, tracker=\"bytetrack.yaml\")\n",
        "        # results = model.track(\"/media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/sample_video1.mp4\", show=True, save=True, tracker=\"bytetrack.yaml\")  # with ByteTrack\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # Display the annotated frame\n",
        "        cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    else:\n",
        "        # Break the loop if the end of the video is reached\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close the display window\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import threading\n",
        "\n",
        "# import cv2\n",
        "\n",
        "# from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# def run_tracker_in_thread(filename, model, file_index):\n",
        "#     \"\"\"\n",
        "#     Runs a video file or webcam stream concurrently with the YOLOv8 model using threading.\n",
        "\n",
        "#     This function captures video frames from a given file or camera source and utilizes the YOLOv8 model for object\n",
        "#     tracking. The function runs in its own thread for concurrent processing.\n",
        "\n",
        "#     Args:\n",
        "#         filename (str): The path to the video file or the identifier for the webcam/external camera source.\n",
        "#         model (obj): The YOLOv8 model object.\n",
        "#         file_index (int): An index to uniquely identify the file being processed, used for display purposes.\n",
        "\n",
        "#     Note:\n",
        "#         Press 'q' to quit the video display window.\n",
        "#     \"\"\"\n",
        "#     # filename=\"/media/supun/Learning Hub/AI & Machine Learning/Company Projects/Foodcity Person Detection/TASKS/task 3-person tracking/sample_video1.mp4\"\n",
        "#     video = cv2.VideoCapture(filename)  # Read the video file\n",
        "\n",
        "#     while True:\n",
        "#         ret, frame = video.read()  # Read the video frames\n",
        "\n",
        "#         # Exit the loop if no more frames in either video\n",
        "#         if not ret:\n",
        "#             break\n",
        "\n",
        "#         # Track objects in frames if available\n",
        "#         results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")\n",
        "#         res_plotted = results[0].plot()\n",
        "#         cv2.imshow(f\"Tracking_Stream_{file_index}\", res_plotted)\n",
        "\n",
        "#         key = cv2.waitKey(1)\n",
        "#         if key == ord(\"q\"):\n",
        "#             break\n",
        "\n",
        "#     # Release video sources\n",
        "#     video.release()\n",
        "\n",
        "\n",
        "# # Load the models\n",
        "# model1 = YOLO(\"use_custom \")\n",
        "# model2 = YOLO(\"yolov8n-seg.pt\")\n",
        "\n",
        "# # Define the video files for the trackers\n",
        "# video_file1 = \"path\"  # Path to video file, 0 for webcam\n",
        "# video_file2 = 0  # Path to video file, 0 for webcam, 1 for external camera\n",
        "\n",
        "# # Create the tracker threads\n",
        "# tracker_thread1 = threading.Thread(target=run_tracker_in_thread, args=(video_file1, model1, 1), daemon=True)\n",
        "# tracker_thread2 = threading.Thread(target=run_tracker_in_thread, args=(video_file2, model2, 2), daemon=True)\n",
        "\n",
        "# # Start the tracker threads\n",
        "# tracker_thread1.start()\n",
        "# tracker_thread2.start()\n",
        "\n",
        "# # Wait for the tracker threads to finish\n",
        "# tracker_thread1.join()\n",
        "# tracker_thread2.join()\n",
        "\n",
        "# # Clean up and close windows\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **People Counting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[ WARN:0@381.432] global cap.cpp:643 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
            "\n",
            "OpenCV(4.10.0) /home/conda/feedstock_root/build_artifacts/libopencv_1718892979884/work/modules/videoio/src/cap_images.cpp:430: error: (-215:Assertion failed) !filename_pattern.empty() in function 'open'\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Polygon Counter Initiated.\n",
            "\n",
            "0: 384x640 25 persons, 202.4ms\n",
            "Speed: 1.8ms preprocess, 202.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 274.0ms\n",
            "Speed: 3.4ms preprocess, 274.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 272.1ms\n",
            "Speed: 3.5ms preprocess, 272.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 217.9ms\n",
            "Speed: 5.7ms preprocess, 217.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 206.6ms\n",
            "Speed: 3.7ms preprocess, 206.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 203.9ms\n",
            "Speed: 3.1ms preprocess, 203.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 192.2ms\n",
            "Speed: 4.4ms preprocess, 192.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 138.3ms\n",
            "Speed: 3.6ms preprocess, 138.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 188.0ms\n",
            "Speed: 4.4ms preprocess, 188.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 200.4ms\n",
            "Speed: 3.2ms preprocess, 200.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 157.0ms\n",
            "Speed: 3.1ms preprocess, 157.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 170.7ms\n",
            "Speed: 3.9ms preprocess, 170.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 191.7ms\n",
            "Speed: 2.6ms preprocess, 191.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 185.4ms\n",
            "Speed: 4.2ms preprocess, 185.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 151.9ms\n",
            "Speed: 5.1ms preprocess, 151.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 234.5ms\n",
            "Speed: 2.6ms preprocess, 234.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 340.0ms\n",
            "Speed: 6.4ms preprocess, 340.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 232.6ms\n",
            "Speed: 5.0ms preprocess, 232.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 246.1ms\n",
            "Speed: 4.0ms preprocess, 246.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 150.8ms\n",
            "Speed: 2.6ms preprocess, 150.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 148.7ms\n",
            "Speed: 4.1ms preprocess, 148.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 161.8ms\n",
            "Speed: 2.1ms preprocess, 161.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 140.2ms\n",
            "Speed: 2.4ms preprocess, 140.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 173.3ms\n",
            "Speed: 2.3ms preprocess, 173.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 198.1ms\n",
            "Speed: 25.7ms preprocess, 198.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 206.3ms\n",
            "Speed: 2.0ms preprocess, 206.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 208.8ms\n",
            "Speed: 3.0ms preprocess, 208.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 204.5ms\n",
            "Speed: 3.7ms preprocess, 204.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 177.9ms\n",
            "Speed: 2.3ms preprocess, 177.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 159.1ms\n",
            "Speed: 3.0ms preprocess, 159.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 138.0ms\n",
            "Speed: 2.9ms preprocess, 138.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 137.0ms\n",
            "Speed: 3.0ms preprocess, 137.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 183.9ms\n",
            "Speed: 2.8ms preprocess, 183.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 250.2ms\n",
            "Speed: 4.0ms preprocess, 250.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 207.3ms\n",
            "Speed: 2.3ms preprocess, 207.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 248.1ms\n",
            "Speed: 2.9ms preprocess, 248.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 279.2ms\n",
            "Speed: 4.1ms preprocess, 279.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 170.9ms\n",
            "Speed: 2.5ms preprocess, 170.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 169.1ms\n",
            "Speed: 3.1ms preprocess, 169.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 230.8ms\n",
            "Speed: 3.0ms preprocess, 230.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 216.0ms\n",
            "Speed: 2.5ms preprocess, 216.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 259.8ms\n",
            "Speed: 31.3ms preprocess, 259.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 306.0ms\n",
            "Speed: 4.5ms preprocess, 306.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 304.0ms\n",
            "Speed: 4.6ms preprocess, 304.0ms inference, 29.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 213.1ms\n",
            "Speed: 2.6ms preprocess, 213.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 220.5ms\n",
            "Speed: 3.4ms preprocess, 220.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 189.7ms\n",
            "Speed: 2.7ms preprocess, 189.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 265.0ms\n",
            "Speed: 4.0ms preprocess, 265.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 275.6ms\n",
            "Speed: 2.8ms preprocess, 275.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 195.8ms\n",
            "Speed: 2.5ms preprocess, 195.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 191.3ms\n",
            "Speed: 3.7ms preprocess, 191.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 233.3ms\n",
            "Speed: 4.6ms preprocess, 233.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 207.8ms\n",
            "Speed: 4.0ms preprocess, 207.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 220.7ms\n",
            "Speed: 2.7ms preprocess, 220.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 214.3ms\n",
            "Speed: 3.3ms preprocess, 214.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 188.9ms\n",
            "Speed: 4.9ms preprocess, 188.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 267.4ms\n",
            "Speed: 2.7ms preprocess, 267.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 232.7ms\n",
            "Speed: 5.4ms preprocess, 232.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 272.4ms\n",
            "Speed: 2.7ms preprocess, 272.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 266.1ms\n",
            "Speed: 2.8ms preprocess, 266.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 427.0ms\n",
            "Speed: 6.6ms preprocess, 427.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 173.6ms\n",
            "Speed: 4.2ms preprocess, 173.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 224.1ms\n",
            "Speed: 3.6ms preprocess, 224.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 228.1ms\n",
            "Speed: 3.3ms preprocess, 228.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 219.4ms\n",
            "Speed: 3.7ms preprocess, 219.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 210.3ms\n",
            "Speed: 2.9ms preprocess, 210.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 179.0ms\n",
            "Speed: 4.1ms preprocess, 179.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 248.5ms\n",
            "Speed: 3.3ms preprocess, 248.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 267.9ms\n",
            "Speed: 2.7ms preprocess, 267.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 231.3ms\n",
            "Speed: 4.1ms preprocess, 231.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 171.3ms\n",
            "Speed: 3.2ms preprocess, 171.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 181.5ms\n",
            "Speed: 4.0ms preprocess, 181.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 232.5ms\n",
            "Speed: 5.7ms preprocess, 232.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 230.5ms\n",
            "Speed: 2.5ms preprocess, 230.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 241.1ms\n",
            "Speed: 2.7ms preprocess, 241.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 213.7ms\n",
            "Speed: 6.1ms preprocess, 213.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 267.0ms\n",
            "Speed: 26.5ms preprocess, 267.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 253.0ms\n",
            "Speed: 2.6ms preprocess, 253.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 208.8ms\n",
            "Speed: 3.0ms preprocess, 208.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 199.2ms\n",
            "Speed: 2.4ms preprocess, 199.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 181.8ms\n",
            "Speed: 3.3ms preprocess, 181.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 139.5ms\n",
            "Speed: 2.7ms preprocess, 139.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 152.0ms\n",
            "Speed: 5.4ms preprocess, 152.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 168.0ms\n",
            "Speed: 5.5ms preprocess, 168.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 204.9ms\n",
            "Speed: 3.3ms preprocess, 204.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 206.2ms\n",
            "Speed: 2.9ms preprocess, 206.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 254.6ms\n",
            "Speed: 3.7ms preprocess, 254.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 231.7ms\n",
            "Speed: 3.4ms preprocess, 231.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 290.8ms\n",
            "Speed: 2.7ms preprocess, 290.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 265.3ms\n",
            "Speed: 5.5ms preprocess, 265.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 295.4ms\n",
            "Speed: 3.5ms preprocess, 295.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 212.1ms\n",
            "Speed: 6.2ms preprocess, 212.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 190.5ms\n",
            "Speed: 3.5ms preprocess, 190.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 220.8ms\n",
            "Speed: 4.2ms preprocess, 220.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 271.2ms\n",
            "Speed: 2.9ms preprocess, 271.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 221.9ms\n",
            "Speed: 4.2ms preprocess, 221.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 319.8ms\n",
            "Speed: 5.9ms preprocess, 319.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 216.0ms\n",
            "Speed: 3.3ms preprocess, 216.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 395.0ms\n",
            "Speed: 41.5ms preprocess, 395.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 351.1ms\n",
            "Speed: 6.1ms preprocess, 351.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 436.2ms\n",
            "Speed: 3.9ms preprocess, 436.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 375.6ms\n",
            "Speed: 2.9ms preprocess, 375.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 445.7ms\n",
            "Speed: 5.1ms preprocess, 445.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 306.7ms\n",
            "Speed: 6.6ms preprocess, 306.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 284.4ms\n",
            "Speed: 8.0ms preprocess, 284.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 234.0ms\n",
            "Speed: 5.2ms preprocess, 234.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 212.8ms\n",
            "Speed: 4.1ms preprocess, 212.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 153.3ms\n",
            "Speed: 3.6ms preprocess, 153.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 214.7ms\n",
            "Speed: 3.0ms preprocess, 214.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 191.7ms\n",
            "Speed: 2.3ms preprocess, 191.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 215.3ms\n",
            "Speed: 4.9ms preprocess, 215.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 264.3ms\n",
            "Speed: 5.0ms preprocess, 264.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 244.9ms\n",
            "Speed: 3.2ms preprocess, 244.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 199.9ms\n",
            "Speed: 3.2ms preprocess, 199.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 190.6ms\n",
            "Speed: 3.1ms preprocess, 190.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 188.3ms\n",
            "Speed: 3.4ms preprocess, 188.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 227.4ms\n",
            "Speed: 2.6ms preprocess, 227.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 245.0ms\n",
            "Speed: 4.6ms preprocess, 245.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 197.6ms\n",
            "Speed: 2.9ms preprocess, 197.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 189.1ms\n",
            "Speed: 6.1ms preprocess, 189.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 315.0ms\n",
            "Speed: 4.3ms preprocess, 315.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 284.8ms\n",
            "Speed: 4.1ms preprocess, 284.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 275.8ms\n",
            "Speed: 4.5ms preprocess, 275.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 197.4ms\n",
            "Speed: 37.0ms preprocess, 197.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 244.7ms\n",
            "Speed: 3.3ms preprocess, 244.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 192.1ms\n",
            "Speed: 3.5ms preprocess, 192.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 237.2ms\n",
            "Speed: 3.1ms preprocess, 237.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 191.9ms\n",
            "Speed: 4.4ms preprocess, 191.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 198.9ms\n",
            "Speed: 3.3ms preprocess, 198.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 190.8ms\n",
            "Speed: 4.0ms preprocess, 190.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 182.1ms\n",
            "Speed: 3.2ms preprocess, 182.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 268.7ms\n",
            "Speed: 34.4ms preprocess, 268.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 263.9ms\n",
            "Speed: 3.3ms preprocess, 263.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 267.7ms\n",
            "Speed: 3.8ms preprocess, 267.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 298.4ms\n",
            "Speed: 3.4ms preprocess, 298.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 264.9ms\n",
            "Speed: 3.5ms preprocess, 264.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 271.2ms\n",
            "Speed: 3.8ms preprocess, 271.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 240.6ms\n",
            "Speed: 4.7ms preprocess, 240.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 246.3ms\n",
            "Speed: 2.9ms preprocess, 246.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 200.4ms\n",
            "Speed: 2.7ms preprocess, 200.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 195.6ms\n",
            "Speed: 2.6ms preprocess, 195.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 267.4ms\n",
            "Speed: 2.9ms preprocess, 267.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 197.0ms\n",
            "Speed: 2.4ms preprocess, 197.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 189.8ms\n",
            "Speed: 3.0ms preprocess, 189.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 239.4ms\n",
            "Speed: 2.8ms preprocess, 239.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 176.0ms\n",
            "Speed: 38.7ms preprocess, 176.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 184.5ms\n",
            "Speed: 3.1ms preprocess, 184.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 191.5ms\n",
            "Speed: 3.1ms preprocess, 191.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 210.8ms\n",
            "Speed: 5.6ms preprocess, 210.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 219.0ms\n",
            "Speed: 3.6ms preprocess, 219.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 205.5ms\n",
            "Speed: 4.9ms preprocess, 205.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 183.2ms\n",
            "Speed: 4.0ms preprocess, 183.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 194.2ms\n",
            "Speed: 3.2ms preprocess, 194.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 243.1ms\n",
            "Speed: 3.5ms preprocess, 243.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 191.4ms\n",
            "Speed: 3.9ms preprocess, 191.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 233.1ms\n",
            "Speed: 4.0ms preprocess, 233.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 184.9ms\n",
            "Speed: 2.6ms preprocess, 184.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 206.8ms\n",
            "Speed: 2.5ms preprocess, 206.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 188.8ms\n",
            "Speed: 2.3ms preprocess, 188.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 189.0ms\n",
            "Speed: 2.4ms preprocess, 189.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 265.6ms\n",
            "Speed: 2.6ms preprocess, 265.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 266.9ms\n",
            "Speed: 5.4ms preprocess, 266.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 210.2ms\n",
            "Speed: 5.5ms preprocess, 210.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 248.5ms\n",
            "Speed: 3.7ms preprocess, 248.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 284.8ms\n",
            "Speed: 6.5ms preprocess, 284.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 194.1ms\n",
            "Speed: 4.4ms preprocess, 194.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 191.9ms\n",
            "Speed: 7.8ms preprocess, 191.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 188.4ms\n",
            "Speed: 4.2ms preprocess, 188.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 262.3ms\n",
            "Speed: 4.7ms preprocess, 262.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 289.2ms\n",
            "Speed: 3.3ms preprocess, 289.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 283.9ms\n",
            "Speed: 4.8ms preprocess, 283.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 277.3ms\n",
            "Speed: 2.8ms preprocess, 277.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 178.5ms\n",
            "Speed: 3.0ms preprocess, 178.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 187.8ms\n",
            "Speed: 3.9ms preprocess, 187.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 184.4ms\n",
            "Speed: 3.9ms preprocess, 184.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 188.4ms\n",
            "Speed: 3.1ms preprocess, 188.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 282.5ms\n",
            "Speed: 45.7ms preprocess, 282.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 289.6ms\n",
            "Speed: 7.3ms preprocess, 289.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 280.6ms\n",
            "Speed: 9.1ms preprocess, 280.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 298.5ms\n",
            "Speed: 35.8ms preprocess, 298.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 303.6ms\n",
            "Speed: 6.1ms preprocess, 303.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 305.3ms\n",
            "Speed: 5.8ms preprocess, 305.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 217.9ms\n",
            "Speed: 5.0ms preprocess, 217.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 194.8ms\n",
            "Speed: 3.2ms preprocess, 194.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 183.0ms\n",
            "Speed: 3.3ms preprocess, 183.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 247.2ms\n",
            "Speed: 2.5ms preprocess, 247.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 195.1ms\n",
            "Speed: 5.4ms preprocess, 195.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 229.0ms\n",
            "Speed: 3.8ms preprocess, 229.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 234.5ms\n",
            "Speed: 5.8ms preprocess, 234.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 246.4ms\n",
            "Speed: 3.7ms preprocess, 246.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 180.7ms\n",
            "Speed: 3.3ms preprocess, 180.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 184.7ms\n",
            "Speed: 4.7ms preprocess, 184.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 179.8ms\n",
            "Speed: 2.9ms preprocess, 179.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 271.4ms\n",
            "Speed: 5.3ms preprocess, 271.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 189.6ms\n",
            "Speed: 5.1ms preprocess, 189.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 192.1ms\n",
            "Speed: 5.1ms preprocess, 192.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 199.0ms\n",
            "Speed: 4.3ms preprocess, 199.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 271.5ms\n",
            "Speed: 6.5ms preprocess, 271.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 238.9ms\n",
            "Speed: 6.1ms preprocess, 238.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 193.4ms\n",
            "Speed: 5.3ms preprocess, 193.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 187.4ms\n",
            "Speed: 5.7ms preprocess, 187.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 226.5ms\n",
            "Speed: 6.4ms preprocess, 226.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 193.1ms\n",
            "Speed: 4.2ms preprocess, 193.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 188.2ms\n",
            "Speed: 6.5ms preprocess, 188.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 197.3ms\n",
            "Speed: 3.1ms preprocess, 197.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 269.5ms\n",
            "Speed: 2.8ms preprocess, 269.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 189.1ms\n",
            "Speed: 2.9ms preprocess, 189.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 202.9ms\n",
            "Speed: 4.7ms preprocess, 202.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 246.6ms\n",
            "Speed: 3.5ms preprocess, 246.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 227.0ms\n",
            "Speed: 4.5ms preprocess, 227.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 270.1ms\n",
            "Speed: 2.4ms preprocess, 270.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 332.4ms\n",
            "Speed: 3.2ms preprocess, 332.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 428.2ms\n",
            "Speed: 55.3ms preprocess, 428.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 403.7ms\n",
            "Speed: 8.7ms preprocess, 403.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 458.3ms\n",
            "Speed: 39.5ms preprocess, 458.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 484.2ms\n",
            "Speed: 10.5ms preprocess, 484.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 375.2ms\n",
            "Speed: 8.4ms preprocess, 375.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 315.1ms\n",
            "Speed: 6.1ms preprocess, 315.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 343.7ms\n",
            "Speed: 6.4ms preprocess, 343.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 294.5ms\n",
            "Speed: 3.2ms preprocess, 294.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 344.0ms\n",
            "Speed: 5.8ms preprocess, 344.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 300.5ms\n",
            "Speed: 45.3ms preprocess, 300.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 282.8ms\n",
            "Speed: 5.9ms preprocess, 282.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 234.1ms\n",
            "Speed: 5.2ms preprocess, 234.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 192.1ms\n",
            "Speed: 6.3ms preprocess, 192.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 231.4ms\n",
            "Speed: 3.2ms preprocess, 231.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 238.0ms\n",
            "Speed: 2.5ms preprocess, 238.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 406.4ms\n",
            "Speed: 6.1ms preprocess, 406.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 384.7ms\n",
            "Speed: 3.6ms preprocess, 384.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 407.9ms\n",
            "Speed: 5.8ms preprocess, 407.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 304.8ms\n",
            "Speed: 6.0ms preprocess, 304.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 255.0ms\n",
            "Speed: 3.2ms preprocess, 255.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 248.8ms\n",
            "Speed: 3.4ms preprocess, 248.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 185.8ms\n",
            "Speed: 2.9ms preprocess, 185.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 202.8ms\n",
            "Speed: 3.3ms preprocess, 202.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 146.4ms\n",
            "Speed: 5.5ms preprocess, 146.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 179.7ms\n",
            "Speed: 3.6ms preprocess, 179.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 168.1ms\n",
            "Speed: 2.8ms preprocess, 168.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 153.4ms\n",
            "Speed: 4.3ms preprocess, 153.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 160.4ms\n",
            "Speed: 3.4ms preprocess, 160.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 142.1ms\n",
            "Speed: 4.7ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 172.1ms\n",
            "Speed: 4.0ms preprocess, 172.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 184.5ms\n",
            "Speed: 5.2ms preprocess, 184.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 167.6ms\n",
            "Speed: 3.0ms preprocess, 167.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 201.6ms\n",
            "Speed: 3.1ms preprocess, 201.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 234.1ms\n",
            "Speed: 2.7ms preprocess, 234.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 399.7ms\n",
            "Speed: 7.1ms preprocess, 399.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 436.7ms\n",
            "Speed: 12.2ms preprocess, 436.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 370.8ms\n",
            "Speed: 7.4ms preprocess, 370.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 319.5ms\n",
            "Speed: 4.2ms preprocess, 319.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 284.9ms\n",
            "Speed: 3.3ms preprocess, 284.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 284.8ms\n",
            "Speed: 5.5ms preprocess, 284.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 232.6ms\n",
            "Speed: 3.5ms preprocess, 232.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 173.9ms\n",
            "Speed: 7.6ms preprocess, 173.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 191.9ms\n",
            "Speed: 3.3ms preprocess, 191.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 212.4ms\n",
            "Speed: 2.5ms preprocess, 212.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 197.2ms\n",
            "Speed: 5.7ms preprocess, 197.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 162.4ms\n",
            "Speed: 3.6ms preprocess, 162.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 266.7ms\n",
            "Speed: 6.3ms preprocess, 266.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 289.9ms\n",
            "Speed: 4.2ms preprocess, 289.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 250.0ms\n",
            "Speed: 7.1ms preprocess, 250.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 223.7ms\n",
            "Speed: 4.1ms preprocess, 223.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 235.0ms\n",
            "Speed: 3.2ms preprocess, 235.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 182.5ms\n",
            "Speed: 4.4ms preprocess, 182.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 228.6ms\n",
            "Speed: 3.8ms preprocess, 228.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 225.7ms\n",
            "Speed: 4.2ms preprocess, 225.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 242.7ms\n",
            "Speed: 5.5ms preprocess, 242.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 179.3ms\n",
            "Speed: 2.1ms preprocess, 179.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 179.4ms\n",
            "Speed: 2.9ms preprocess, 179.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 204.3ms\n",
            "Speed: 8.6ms preprocess, 204.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 204.6ms\n",
            "Speed: 5.2ms preprocess, 204.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 222.3ms\n",
            "Speed: 4.3ms preprocess, 222.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 266.9ms\n",
            "Speed: 4.6ms preprocess, 266.9ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 443.3ms\n",
            "Speed: 3.3ms preprocess, 443.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 325.8ms\n",
            "Speed: 6.0ms preprocess, 325.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 299.9ms\n",
            "Speed: 3.5ms preprocess, 299.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 219.2ms\n",
            "Speed: 3.5ms preprocess, 219.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 191.6ms\n",
            "Speed: 3.2ms preprocess, 191.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 375.5ms\n",
            "Speed: 5.9ms preprocess, 375.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 267.5ms\n",
            "Speed: 3.1ms preprocess, 267.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 223.6ms\n",
            "Speed: 4.1ms preprocess, 223.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 235.3ms\n",
            "Speed: 2.2ms preprocess, 235.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 205.4ms\n",
            "Speed: 2.8ms preprocess, 205.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 245.7ms\n",
            "Speed: 53.9ms preprocess, 245.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 192.3ms\n",
            "Speed: 4.4ms preprocess, 192.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 235.4ms\n",
            "Speed: 5.3ms preprocess, 235.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 244.0ms\n",
            "Speed: 3.9ms preprocess, 244.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 287.7ms\n",
            "Speed: 7.4ms preprocess, 287.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 279.5ms\n",
            "Speed: 4.9ms preprocess, 279.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 271.8ms\n",
            "Speed: 5.1ms preprocess, 271.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 172.0ms\n",
            "Speed: 2.4ms preprocess, 172.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 202.7ms\n",
            "Speed: 4.0ms preprocess, 202.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 232.9ms\n",
            "Speed: 4.3ms preprocess, 232.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 286.7ms\n",
            "Speed: 4.7ms preprocess, 286.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 271.9ms\n",
            "Speed: 6.5ms preprocess, 271.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 258.8ms\n",
            "Speed: 5.5ms preprocess, 258.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 290.3ms\n",
            "Speed: 6.4ms preprocess, 290.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 257.0ms\n",
            "Speed: 5.6ms preprocess, 257.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 275.8ms\n",
            "Speed: 5.4ms preprocess, 275.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 268.7ms\n",
            "Speed: 3.9ms preprocess, 268.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 241.1ms\n",
            "Speed: 32.8ms preprocess, 241.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 190.5ms\n",
            "Speed: 4.1ms preprocess, 190.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 232.3ms\n",
            "Speed: 2.9ms preprocess, 232.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 179.5ms\n",
            "Speed: 3.4ms preprocess, 179.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 162.8ms\n",
            "Speed: 38.1ms preprocess, 162.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 165.1ms\n",
            "Speed: 3.7ms preprocess, 165.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 186.9ms\n",
            "Speed: 2.9ms preprocess, 186.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 289.2ms\n",
            "Speed: 3.2ms preprocess, 289.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 223.7ms\n",
            "Speed: 40.2ms preprocess, 223.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 240.0ms\n",
            "Speed: 4.6ms preprocess, 240.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 245.4ms\n",
            "Speed: 11.3ms preprocess, 245.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 219.6ms\n",
            "Speed: 5.4ms preprocess, 219.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 278.3ms\n",
            "Speed: 4.4ms preprocess, 278.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 218.1ms\n",
            "Speed: 5.3ms preprocess, 218.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 316.6ms\n",
            "Speed: 9.0ms preprocess, 316.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 179.3ms\n",
            "Speed: 4.9ms preprocess, 179.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 215.1ms\n",
            "Speed: 6.1ms preprocess, 215.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 182.9ms\n",
            "Speed: 4.3ms preprocess, 182.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 226.4ms\n",
            "Speed: 4.5ms preprocess, 226.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 197.1ms\n",
            "Speed: 4.6ms preprocess, 197.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 201.2ms\n",
            "Speed: 3.4ms preprocess, 201.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 183.3ms\n",
            "Speed: 3.2ms preprocess, 183.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 182.0ms\n",
            "Speed: 4.5ms preprocess, 182.0ms inference, 30.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 276.4ms\n",
            "Speed: 7.7ms preprocess, 276.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 264.6ms\n",
            "Speed: 5.7ms preprocess, 264.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 269.8ms\n",
            "Speed: 4.2ms preprocess, 269.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 195.2ms\n",
            "Speed: 7.0ms preprocess, 195.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 177.9ms\n",
            "Speed: 3.2ms preprocess, 177.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 210.7ms\n",
            "Speed: 6.2ms preprocess, 210.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 185.3ms\n",
            "Speed: 3.0ms preprocess, 185.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 230.5ms\n",
            "Speed: 4.4ms preprocess, 230.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 200.9ms\n",
            "Speed: 5.3ms preprocess, 200.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 232.1ms\n",
            "Speed: 6.8ms preprocess, 232.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 307.4ms\n",
            "Speed: 7.3ms preprocess, 307.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 322.5ms\n",
            "Speed: 8.2ms preprocess, 322.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 250.1ms\n",
            "Speed: 5.8ms preprocess, 250.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 260.5ms\n",
            "Speed: 5.3ms preprocess, 260.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 193.0ms\n",
            "Speed: 6.2ms preprocess, 193.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 189.6ms\n",
            "Speed: 5.3ms preprocess, 189.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 203.8ms\n",
            "Speed: 8.8ms preprocess, 203.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 234.3ms\n",
            "Speed: 4.9ms preprocess, 234.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 370.0ms\n",
            "Speed: 7.1ms preprocess, 370.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Video frame is empty or video processing has been successfully completed.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "from ultralytics import YOLO, solutions\n",
        "\n",
        "model = YOLO(\"model/PeopleDetector.pt\")\n",
        "cap = cv2.VideoCapture(\"data/people_walking.webm\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define region points\n",
        "region_points = [\n",
        "    (0, 150), # starting from the top-left corner\n",
        "    (2080, 150), # ending at the top-right corner \n",
        "    (2080, 500), # ending at the bottom-right corner\n",
        "    (0, 500)] # ending at the bottom-left corner\n",
        "\n",
        "# Video writer\n",
        "video_writer = cv2.VideoWriter(\"object_counting_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# Init Object Counter\n",
        "counter = solutions.ObjectCounter(\n",
        "    view_img=True,\n",
        "    reg_pts=region_points,\n",
        "    classes_names=model.names,\n",
        "    draw_tracks=True,\n",
        "    line_thickness=2,\n",
        "    count_reg_color=(255, 0, 255),\n",
        "\n",
        ")\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "    tracks = model.track(im0, persist=True, show=False, conf=0.3, iou=0.5, tracker=\"bytetrack.yaml\")\n",
        "\n",
        "    im0 = counter.start_counting(im0, tracks) # Count objects in the frame\n",
        "    video_writer.write(im0)\n",
        "\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
